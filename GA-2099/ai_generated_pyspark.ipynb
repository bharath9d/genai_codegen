{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Superstore Sales Data\n# MAGIC This notebook performs an ETL process on superstore sales data using PySpark in Databricks.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import DateType\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Load Data\n# MAGIC Load data from Unity Catalog tables.\n\n# COMMAND ----------\n\ndef load_data():\n    try:\n        logger.info(\"Loading data from Unity Catalog tables...\")\n        orders_central_df = spark.table(\"catalog.db.orders_central\")\n        orders_west_df = spark.table(\"catalog.db.orders_west\")\n        orders_east_df = spark.table(\"catalog.db.orders_east\")\n        orders_south_df = spark.table(\"catalog.db.orders_south\")\n        quota_df = spark.table(\"catalog.db.quota\")\n        returns_df = spark.table(\"catalog.db.returns\")\n        logger.info(\"Data loaded successfully.\")\n        return orders_central_df, orders_west_df, orders_east_df, orders_south_df, quota_df, returns_df\n    except Exception as e:\n        logger.error(f\"Error loading data: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Transform Data\n# MAGIC Perform data transformations on the loaded data.\n\n# COMMAND ----------\n\ndef transform_data(orders_central_df, orders_west_df, orders_east_df, orders_south_df, quota_df, returns_df):\n    try:\n        logger.info(\"Starting data transformation...\")\n\n        # Standardize date fields for orders_central_df\n        orders_central_df = orders_central_df.withColumn(\n            \"Order Date\", \n            F.concat_ws(\"/\", F.col(\"Order Day\"), F.col(\"Order Month\"), F.col(\"Order Year\")).cast(DateType())\n        ).withColumn(\n            \"Ship Date\", \n            F.concat_ws(\"/\", F.col(\"Ship Day\"), F.col(\"Ship Month\"), F.col(\"Ship Year\")).cast(DateType())\n        )\n\n        # Exclude null Order IDs\n        orders_central_df = orders_central_df.filter(F.col(\"Order ID\").isNotNull())\n\n        # Add calculated fields\n        orders_central_df = orders_central_df.withColumn(\n            \"Days to Ship\", \n            F.datediff(F.col(\"Ship Date\"), F.col(\"Order Date\"))\n        ).withColumn(\n            \"Returned?\", \n            F.when(F.col(\"Return Reason\").isNotNull(), \"Yes\").otherwise(\"No\")\n        )\n\n        # Standardize state names\n        state_mapping = {\"California\": \"CA\", \"New York\": \"NY\"}  # Example mapping\n        orders_central_df = orders_central_df.replace(state_mapping, subset=[\"State\"])\n\n        # Union all orders\n        all_orders_df = orders_central_df.unionByName(orders_west_df).unionByName(orders_east_df).unionByName(orders_south_df)\n\n        # Unpivot quota data\n        quota_unpivot_df = quota_df.selectExpr(\n            \"Region\", \n            \"stack(4, '2015', `2015`, '2016', `2016`, '2017', `2017`, '2018', `2018`) as (Year, Quota)\"\n        )\n\n        logger.info(\"Data transformation completed successfully.\")\n        return all_orders_df, quota_unpivot_df\n    except Exception as e:\n        logger.error(f\"Error during data transformation: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Write Data\n# MAGIC Write the transformed data back to Unity Catalog tables.\n\n# COMMAND ----------\n\ndef write_data(all_orders_df, quota_unpivot_df):\n    try:\n        logger.info(\"Writing data to Unity Catalog tables...\")\n        all_orders_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.superstore_sales\")\n        quota_unpivot_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.db.sales_quota\")\n        logger.info(\"Data written successfully.\")\n    except Exception as e:\n        logger.error(f\"Error writing data: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Main ETL Process\n# MAGIC Execute the main ETL process.\n\n# COMMAND ----------\n\ndef main():\n    try:\n        # Load data\n        orders_central_df, orders_west_df, orders_east_df, orders_south_df, quota_df, returns_df = load_data()\n\n        # Transform data\n        all_orders_df, quota_unpivot_df = transform_data(\n            orders_central_df, orders_west_df, orders_east_df, orders_south_df, quota_df, returns_df\n        )\n\n        # Write data\n        write_data(all_orders_df, quota_unpivot_df)\n\n    except Exception as e:\n        logger.error(f\"ETL process failed: {e}\")\n\n# Execute the main process\nif __name__ == \"__main__\":\n    main()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}