{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40b54fed-f360-4754-9ca3-3883c4b0350e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # ETL Process for Cardinal Health Data\n",
    "# MAGIC This notebook performs an ETL process on data from Unity Catalog tables, including data loading, integration, calculations, filtering, sorting, and output.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import logging\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "try:\n",
    "    # Step 1: Data Loading\n",
    "    logger.info(\"Loading data from Unity Catalog tables.\")\n",
    "    associates_employment_df = spark.table(\"genai_demo.cardinal_health.associates_employment\")\n",
    "    compensation_guidelines_df = spark.table(\"genai_demo.cardinal_health.compensation_guidelines\")\n",
    "    hospital_assignments_df = spark.table(\"genai_demo.cardinal_health.hospital_assignments\")\n",
    "    hospitals_stats_df = spark.table(\"genai_demo.cardinal_health.hospitals_stats\")\n",
    "    logistics_channels_df = spark.table(\"genai_demo.cardinal_health.logistics_channels\")\n",
    "    growth_opportunities_df = spark.table(\"genai_demo.cardinal_health.growth_opportunities\")\n",
    "    historical_sales_trending_df = spark.table(\"genai_demo.cardinal_health.historical_sales_trending\")\n",
    "    company_goals_df = spark.table(\"genai_demo.cardinal_health.company_goals_1\")\n",
    "    third_party_trends_df = spark.table(\"genai_demo.cardinal_health.third_party_trends\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 2: Data Integration\n",
    "    logger.info(\"Performing data integration through joins.\")\n",
    "    employment_compensation_df = associates_employment_df.join(\n",
    "        compensation_guidelines_df,\n",
    "        on=\"Associate_ID\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    hospital_assignments_df = hospital_assignments_df.join(\n",
    "        hospitals_stats_df,\n",
    "        on=[\"Hospital_ID\", \"Hospital_Name\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 3: Custom Calculations\n",
    "    logger.info(\"Calculating total compensation and projected revenue.\")\n",
    "    employment_compensation_df = employment_compensation_df.withColumn(\n",
    "        \"Total_Compensation\",\n",
    "        F.col(\"Base_Salary\") + (F.col(\"Commission_Percentage\") * F.col(\"Base_Salary\")) + F.col(\"Bonus\")\n",
    "    )\n",
    "\n",
    "    historical_sales_trending_df = historical_sales_trending_df.withColumn(\n",
    "        \"Projected_Revenue\",\n",
    "        F.expr(\"\"\"\n",
    "            CASE\n",
    "                WHEN Target_Year = 2024 THEN Sales_Revenue * (Projected_Sales_Growth_Rate / 100)\n",
    "                WHEN Target_Year = 2025 THEN Sales_Revenue * (1 + Projected_Sales_Growth_Rate / 100)\n",
    "                WHEN Target_Year = 2026 THEN Sales_Revenue * (1 + Projected_Sales_Growth_Rate / 100)\n",
    "                ELSE Sales_Revenue\n",
    "            END\n",
    "        \"\"\")\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 4: Data Filtering and Selection\n",
    "    logger.info(\"Filtering and selecting relevant data.\")\n",
    "    filtered_df = historical_sales_trending_df.filter(F.col(\"Target_Year\") > 2023)\n",
    "\n",
    "    selected_df = filtered_df.select(\n",
    "        \"Hospital_ID\", \"Channel_Type\", \"Growth_Opportunities\", \"Projected_Growth_Rate\", \"Market_Potential\", \"Expected_ROI\"\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 5: Data Sorting\n",
    "    logger.info(\"Sorting data by target year.\")\n",
    "    sorted_df = selected_df.orderBy(\"Target_Year\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 6: Data Output\n",
    "    logger.info(\"Writing the final output to Unity Catalog table.\")\n",
    "    sorted_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.cardinal_health.hospitals_output\")\n",
    "\n",
    "    logger.info(\"ETL process completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(\"An error occurred during the ETL process.\", exc_info=True)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ai_generated_pyspark_code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
