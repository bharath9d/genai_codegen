{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9616bc35-3b40-40b0-8c70-1ac818e046a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # ETL Process for Superstore Sales Data\n",
    "# MAGIC This notebook performs an ETL process on Superstore sales data using PySpark.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import logging\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "try:\n",
    "    # Step 1: Data Loading\n",
    "    logger.info(\"Loading data from Unity Catalog tables.\")\n",
    "    orders_central_df = spark.table(\"genai_demo.citi.orders_central\")\n",
    "    orders_east_df = spark.table(\"genai_demo.citi.orders_east\")\n",
    "    orders_south_2015_df = spark.table(\"genai_demo.citi.orders_south_2015\")\n",
    "    orders_south_2016_df = spark.table(\"genai_demo.citi.orders_south_2016\")\n",
    "    orders_south_2017_df = spark.table(\"genai_demo.citi.orders_south_2017\")\n",
    "    orders_south_2018_df = spark.table(\"genai_demo.citi.orders_south_2018\")\n",
    "    orders_west_df = spark.table(\"genai_demo.citi.orders_west\")\n",
    "    quota_df = spark.table(\"genai_demo.citi.quota\")\n",
    "    returns_df = spark.table(\"genai_demo.citi.returns\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 2: Data Standardization\n",
    "    logger.info(\"Standardizing data.\")\n",
    "    orders_central_df = orders_central_df.withColumn(\n",
    "        \"Order Date\", \n",
    "        F.concat(F.col(\"Order Day\"), F.lit(\"/\"), F.col(\"Order Month\"), F.lit(\"/\"), F.col(\"Order Year\"))\n",
    "    ).withColumnRenamed(\"Discounts\", \"Discount\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 3: Data Cleaning\n",
    "    logger.info(\"Cleaning data.\")\n",
    "    orders_central_df = orders_central_df.filter(orders_central_df[\"Order ID\"].isNotNull())\n",
    "    orders_central_df = orders_central_df.withColumn(\"Sales\", F.col(\"Sales\").cast(DoubleType()))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 4: Pivoting and Consolidation\n",
    "    logger.info(\"Pivoting and consolidating data.\")\n",
    "    quota_df = quota_df.selectExpr(\"Region\", \"stack(4, '2015', `2015`, '2016', `2016`, '2017', `2017`, '2018', `2018`) as (Year, Quota)\")\n",
    "    all_orders_df = orders_central_df.union(orders_east_df).union(orders_south_2015_df).union(orders_south_2016_df).union(orders_south_2017_df).union(orders_south_2018_df).union(orders_west_df)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 5: Calculated Fields and Enhancements\n",
    "    logger.info(\"Adding calculated fields.\")\n",
    "    all_orders_df = all_orders_df.withColumn(\"Days to Ship\", F.datediff(F.col(\"Ship Date\"), F.col(\"Order Date\")))\n",
    "    all_orders_df = all_orders_df.withColumn(\"Returned?\", F.when(F.col(\"Return Reason\").isNotNull(), \"Yes\").otherwise(\"No\"))\n",
    "    aggregated_df = all_orders_df.groupBy(\"Region\", F.year(\"Order Date\").alias(\"Year of Sale\")).agg(\n",
    "        F.sum(\"Profit\").alias(\"Total Profit\"),\n",
    "        F.sum(\"Sales\").alias(\"Total Sales\"),\n",
    "        F.sum(\"Quantity\").alias(\"Total Quantity\"),\n",
    "        F.avg(\"Discount\").alias(\"Average Discount\")\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 6: Business Rules\n",
    "    logger.info(\"Applying business rules.\")\n",
    "    all_orders_df = all_orders_df.filter((F.col(\"Discount\") < 17) | (F.col(\"Discount\") > 18))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 7: Output Generation\n",
    "    logger.info(\"Writing output to Unity Catalog tables.\")\n",
    "    aggregated_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.annual_regional_performance\")\n",
    "    all_orders_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.superstore_sales\")\n",
    "\n",
    "    logger.info(\"ETL process completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(\"An error occurred during the ETL process.\", exc_info=True)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ai_generated_pyspark_code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
