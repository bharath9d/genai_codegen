{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Customer 360 Data\n# MAGIC This notebook performs an ETL process to integrate and transform data from various Unity Catalog tables into a comprehensive Customer 360 dataset.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import IntegerType, DoubleType, DateType\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\ntry:\n    # Load data from Unity Catalog tables\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    policy_df = spark.table(\"catalog.source_db.policy\")\n    claims_df = spark.table(\"catalog.source_db.claims\")\n    demographics_df = spark.table(\"catalog.source_db.demographics\")\n    scores_df = spark.table(\"catalog.source_db.scores\")\n    aiml_insights_df = spark.table(\"catalog.source_db.aiml_insights\")\n\n# COMMAND ----------\n\n    # Type Conversion\n    logger.info(\"Converting data types...\")\n    policy_df = policy_df.withColumn(\"policy_start_date\", F.to_date(\"policy_start_date\", \"yyyy-MM-dd\")) \\\n                         .withColumn(\"policy_end_date\", F.to_date(\"policy_end_date\", \"yyyy-MM-dd\")) \\\n                         .withColumn(\"policy_term\", policy_df[\"policy_term\"].cast(IntegerType())) \\\n                         .withColumn(\"policy_premium\", policy_df[\"policy_premium\"].cast(DoubleType())) \\\n                         .withColumn(\"total_premium_paid\", policy_df[\"total_premium_paid\"].cast(DoubleType()))\n\n    claims_df = claims_df.withColumn(\"Claim_Date\", F.to_date(\"Claim_Date\", \"yyyy-MM-dd\")) \\\n                         .withColumn(\"Claim_Amount\", claims_df[\"Claim_Amount\"].cast(DoubleType())) \\\n                         .withColumn(\"Claim_Payout\", claims_df[\"Claim_Payout\"].cast(DoubleType()))\n\n    demographics_df = demographics_df.withColumn(\"Date_of_Birth\", F.to_date(\"Date_of_Birth\", \"yyyy-MM-dd\"))\n\n# COMMAND ----------\n\n    # Data Integration\n    logger.info(\"Integrating data...\")\n    demographics_policy_df = demographics_df.join(policy_df, demographics_df.Customer_ID == policy_df.customer_id, \"inner\")\n    integrated_df = demographics_policy_df.join(claims_df, demographics_policy_df.policy_id == claims_df.Policy_ID, \"inner\")\n\n# COMMAND ----------\n\n    # Data Aggregation\n    logger.info(\"Aggregating data...\")\n    aggregated_df = integrated_df.groupBy(\"Customer_ID\").agg(\n        F.count(\"Claim_ID\").alias(\"Total_Claims\"),\n        F.count(\"policy_id\").alias(\"Policy_Count\"),\n        F.max(\"Claim_Date\").alias(\"Recent_Claim_Date\"),\n        F.avg(\"Claim_Amount\").alias(\"Average_Claim_Amount\")\n    )\n\n# COMMAND ----------\n\n    # Custom Calculations\n    logger.info(\"Performing custom calculations...\")\n    final_df = aggregated_df.withColumn(\"Age\", F.datediff(F.current_date(), \"Date_of_Birth\") / 365) \\\n                            .withColumn(\"Claim_To_Premium_Ratio\", F.when(F.col(\"total_premium_paid\") != 0, F.col(\"Claim_Amount\") / F.col(\"total_premium_paid\")).otherwise(0)) \\\n                            .withColumn(\"Claims_Per_Policy\", F.when(F.col(\"Policy_Count\") != 0, F.col(\"Total_Claims\") / F.col(\"Policy_Count\")).otherwise(0)) \\\n                            .withColumn(\"Retention_Rate\", F.lit(0.85)) \\\n                            .withColumn(\"Cross_Sell_Opportunities\", F.lit(\"Multi-Policy Discount, Home Coverage Add-on\")) \\\n                            .withColumn(\"Upsell_Potential\", F.lit(\"Premium Vehicle Coverage\"))\n\n# COMMAND ----------\n\n    # Join with AI/ML Insights and Scores\n    logger.info(\"Joining with AI/ML insights and scores...\")\n    final_df = final_df.join(scores_df, \"Customer_ID\", \"inner\") \\\n                       .join(aiml_insights_df, \"Customer_ID\", \"inner\")\n\n# COMMAND ----------\n\n    # Write to Unity Catalog target table\n    logger.info(\"Writing final data to Unity Catalog target table...\")\n    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.target_db.customer_360\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}