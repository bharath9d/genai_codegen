{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Guardian Data\n# MAGIC This notebook performs an ETL process on data from Unity Catalog tables, integrating and transforming it into a comprehensive dataset.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql.functions import col, to_date, count, avg, max, when, datediff, current_date, lit, broadcast\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\ntry:\n    # Load data from Unity Catalog tables\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    policy_df = spark.table(\"genai_demo.guardian.policy\")\n    claims_df = spark.table(\"genai_demo.guardian.claims\")\n    demographics_df = spark.table(\"genai_demo.guardian.demographics\")\n    scores_df = spark.table(\"genai_demo.guardian.scores\")\n    aiml_insights_df = spark.table(\"genai_demo.guardian.aiml_insights\")\n\n# COMMAND ----------\n\n    # Data Selection and Type Conversion\n    logger.info(\"Selecting relevant fields and performing type conversions...\")\n    demographics_df = demographics_df.select(\n        \"Customer_ID\", \"Customer_Name\", \"Email\", \"Phone_Number\", \"Address\", \"City\", \"State\", \"Postal_Code\",\n        to_date(col(\"Date_of_Birth\"), \"yyyy-MM-dd\").alias(\"Date_of_Birth\"), \"Gender\", \"Marital_Status\",\n        \"Occupation\", \"Income_Level\", \"Customer_Segment\"\n    )\n\n    claims_df = claims_df.select(\n        \"Claim_ID\", \"Policy_ID\", to_date(col(\"Claim_Date\"), \"yyyy-MM-dd\").alias(\"Claim_Date\"),\n        \"Claim_Type\", \"Claim_Status\", col(\"Claim_Amount\").cast(\"double\").alias(\"Claim_Amount\"),\n        col(\"Claim_Payout\").cast(\"double\").alias(\"Claim_Payout\")\n    )\n\n    policy_df = policy_df.select(\n        \"policy_id\", \"customer_id\", \"policy_type\", \"policy_status\",\n        to_date(col(\"policy_start_date\"), \"yyyy-MM-dd\").alias(\"policy_start_date\"),\n        to_date(col(\"policy_end_date\"), \"yyyy-MM-dd\").alias(\"policy_end_date\"),\n        col(\"policy_term\").cast(\"int\").alias(\"policy_term\"),\n        col(\"policy_premium\").cast(\"double\").alias(\"policy_premium\"),\n        col(\"total_premium_paid\").cast(\"double\").alias(\"total_premium_paid\"),\n        \"renewal_status\", \"policy_addons\"\n    )\n\n# COMMAND ----------\n\n    # Data Integration\n    logger.info(\"Performing data integration through joins...\")\n    joined_df = demographics_df.join(policy_df, demographics_df.Customer_ID == policy_df.customer_id, \"inner\") \\\n                               .drop(policy_df.customer_id) \\\n                               .join(claims_df, \"policy_id\", \"inner\")\n\n    # Cache the joined DataFrame if reused\n    joined_df.cache()\n\n# COMMAND ----------\n\n    # Data Aggregation\n    logger.info(\"Aggregating claims data...\")\n    aggregated_df = joined_df.groupBy(\"Customer_ID\").agg(\n        count(\"Claim_ID\").alias(\"Total_Claims\"),\n        count(\"policy_id\").alias(\"Policy_Count\"),\n        max(\"Claim_Date\").alias(\"Recent_Claim_Date\"),\n        avg(\"Claim_Amount\").alias(\"Average_Claim_Amount\")\n    )\n\n# COMMAND ----------\n\n    # Custom Calculations\n    logger.info(\"Implementing custom calculations...\")\n    final_df = aggregated_df.withColumn(\"Age\", datediff(current_date(), col(\"Date_of_Birth\")) / 365) \\\n                            .withColumn(\"Claim_To_Premium_Ratio\", when(col(\"total_premium_paid\") != 0, col(\"Average_Claim_Amount\") / col(\"total_premium_paid\")).otherwise(0)) \\\n                            .withColumn(\"Claims_Per_Policy\", when(col(\"Policy_Count\") != 0, col(\"Total_Claims\") / col(\"Policy_Count\")).otherwise(0)) \\\n                            .withColumn(\"Retention_Rate\", lit(0.85)) \\\n                            .withColumn(\"Cross_Sell_Opportunities\", lit(\"Multi-Policy Discount, Home Coverage Add-on\")) \\\n                            .withColumn(\"Upsell_Potential\", lit(\"Premium Vehicle Coverage\"))\n\n# COMMAND ----------\n\n    # Data Consolidation\n    logger.info(\"Consolidating data into a final comprehensive dataset...\")\n    final_df = final_df.join(broadcast(scores_df), \"Customer_ID\", \"inner\") \\\n                       .join(broadcast(aiml_insights_df), \"Customer_ID\", \"inner\")\n\n# COMMAND ----------\n\n    # Output Data\n    logger.info(\"Writing the final dataset to Unity Catalog table...\")\n    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.guardian.customer_360\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}