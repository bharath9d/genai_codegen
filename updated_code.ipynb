{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Global Indicators\n# MAGIC This notebook performs an ETL process on data from Unity Catalog tables, applying various transformations and writing the results to a Delta table.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import functions as F\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\ntry:\n    # Load data from Unity Catalog tables\n    logger.info(\"Loading data from Unity Catalog tables.\")\n    global_indicators_df = spark.table(\"catalog.source_db.global_world_indicators_2000\")\n    consumer_price_indices_df = spark.table(\"catalog.source_db.ConsumerPriceIndices\")\n\n# COMMAND ----------\n\n    # Transformation: Remove Columns\n    logger.info(\"Removing unnecessary columns.\")\n    columns_to_drop = [\"UnnecessaryColumn1\", \"UnnecessaryColumn2\"]  # Replace with actual column names\n    global_indicators_df = global_indicators_df.drop(*columns_to_drop)\n\n# COMMAND ----------\n\n    # Transformation: Change Column Type\n    logger.info(\"Changing column types.\")\n    if \"GDP\" in global_indicators_df.columns:\n        global_indicators_df = global_indicators_df.withColumn(\"GDP\", F.col(\"GDP\").cast(\"double\"))\n\n# COMMAND ----------\n\n    # Transformation: Remap\n    logger.info(\"Remapping column values.\")\n    global_indicators_df = global_indicators_df.withColumn(\n        \"Ease of Business\",\n        F.when(F.col(\"Ease of Business\") == \"OldValue\", \"NewValue\").otherwise(F.col(\"Ease of Business\"))\n    )\n\n# COMMAND ----------\n\n    # Transformation: Add Column\n    logger.info(\"Adding new column.\")\n    if \"ExistingColumn\" in global_indicators_df.columns:\n        global_indicators_df = global_indicators_df.withColumn(\"NewColumn\", F.col(\"ExistingColumn\") * 2)\n\n# COMMAND ----------\n\n    # Transformation: Rename Column\n    logger.info(\"Renaming columns.\")\n    if \"OldColumnName\" in global_indicators_df.columns:\n        global_indicators_df = global_indicators_df.withColumnRenamed(\"OldColumnName\", \"NewColumnName\")\n\n# COMMAND ----------\n\n    # Transformation: Filter Operation\n    logger.info(\"Applying filter operation.\")\n    if \"Year\" in global_indicators_df.columns:\n        global_indicators_df = global_indicators_df.filter(F.col(\"Year\").cast(\"int\") > 2000)\n\n# COMMAND ----------\n\n    # Transformation: Range Filter\n    logger.info(\"Applying range filter.\")\n    global_indicators_df = global_indicators_df.filter((F.col(\"GDP\") > 1000) & (F.col(\"GDP\") < 5000))\n\n# COMMAND ----------\n\n    # Transformation: Aggregate\n    logger.info(\"Performing aggregation.\")\n    aggregated_df = global_indicators_df.groupBy(\"Country/Region\").agg(F.sum(\"GDP\").alias(\"Total_GDP\"))\n\n# COMMAND ----------\n\n    # Transformation: Unpivot\n    # Implement unpivot logic here\n    logger.info(\"Unpivoting data.\")\n    # Example unpivot logic (to be replaced with actual logic)\n    # unpivoted_df = custom_unpivot_function(aggregated_df)\n\n# COMMAND ----------\n\n    # Join Condition\n    logger.info(\"Joining dataframes.\")\n    # Check for duplicate columns in join\n    common_columns = set(global_indicators_df.columns).intersection(set(consumer_price_indices_df.columns))\n    common_columns.discard(\"Country/Region\")  # Keep the join key\n    consumer_price_indices_df = consumer_price_indices_df.drop(*common_columns)\n\n    final_df = global_indicators_df.join(\n        consumer_price_indices_df,\n        global_indicators_df[\"Country/Region\"] == consumer_price_indices_df[\"Country/Region\"],\n        \"inner\"\n    )\n\n# COMMAND ----------\n\n    # Custom Calculation: Extract Year\n    logger.info(\"Performing custom calculation to extract year.\")\n    final_df = final_df.withColumn(\"Year\", F.substring(F.col(\"Year\").cast(\"string\"), 1, 4))\n\n# COMMAND ----------\n\n    # Write to Delta table\n    logger.info(\"Writing final dataframe to Delta table.\")\n    final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.target_db.Global_Indicators\")\n\n    logger.info(\"ETL process completed successfully.\")\n\n# COMMAND ----------\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}