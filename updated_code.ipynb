{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Global Indicators\n# MAGIC This notebook performs an ETL process on global indicators data using PySpark.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, when, lit, avg, expr, substring\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Load Data from Unity Catalog Tables\n\n# COMMAND ----------\n\ndef main():\n    try:\n        # Load data from Unity Catalog tables\n        logger.info(\"Loading data from Unity Catalog tables.\")\n        indicators_df = spark.table(\"catalog.source_db.global_world_indicators_2000\")\n        cpi_df = spark.table(\"catalog.source_db.ConsumerPriceIndices\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Data Cleaning and Transformation\n\n# COMMAND ----------\n\n        # Remove unnecessary columns\n        logger.info(\"Dropping unnecessary columns.\")\n        # Check if columns exist before dropping\n        columns_to_drop = [\"UnnecessaryColumn1\", \"UnnecessaryColumn2\"]\n        indicators_df = indicators_df.drop(*[col for col in columns_to_drop if col in indicators_df.columns])\n        \n        columns_to_drop_cpi = [\"UnnecessaryColumn3\", \"UnnecessaryColumn4\"]\n        cpi_df = cpi_df.drop(*[col for col in columns_to_drop_cpi if col in cpi_df.columns])\n\n        # Change column types\n        logger.info(\"Changing column types.\")\n        if \"Birth Rate\" in indicators_df.columns:\n            indicators_df = indicators_df.withColumn(\"Birth Rate\", col(\"Birth Rate\").cast(\"double\"))\n\n        # Remap values\n        logger.info(\"Remapping values.\")\n        if \"Region\" in indicators_df.columns:\n            indicators_df = indicators_df.withColumn(\"Region\", when(col(\"Region\") == \"OldValue\", \"NewValue\").otherwise(col(\"Region\")))\n\n        # Add new columns\n        logger.info(\"Adding new columns.\")\n        indicators_df = indicators_df.withColumn(\"NewColumn\", lit(\"DefaultValue\"))\n\n        # Rename columns\n        logger.info(\"Renaming columns.\")\n        if \"OldColumnName\" in indicators_df.columns:\n            indicators_df = indicators_df.withColumnRenamed(\"OldColumnName\", \"NewColumnName\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Filtering and Aggregation\n\n# COMMAND ----------\n\n        # Filter operations\n        logger.info(\"Applying filters.\")\n        if \"Year\" in indicators_df.columns:\n            indicators_df = indicators_df.filter(col(\"Year\") > 2000)\n\n        # Range filter\n        logger.info(\"Applying range filters.\")\n        if \"GDP\" in indicators_df.columns:\n            indicators_df = indicators_df.filter((col(\"GDP\") > 1000) & (col(\"GDP\") < 5000))\n\n        # Aggregate operations\n        logger.info(\"Performing aggregation.\")\n        if \"Country/Region\" in indicators_df.columns and \"GDP\" in indicators_df.columns:\n            aggregated_df = indicators_df.groupBy(\"Country/Region\").agg(avg(\"GDP\").alias(\"Average GDP\"))\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Unpivoting and Joining DataFrames\n\n# COMMAND ----------\n\n        # Unpivot data\n        logger.info(\"Unpivoting data.\")\n        if all(col in indicators_df.columns for col in [\"Birth Rate\", \"GDP\", \"CO2 Emissions\"]):\n            unpivoted_df = indicators_df.selectExpr(\"Country/Region\", \"stack(3, 'Birth Rate', `Birth Rate`, 'GDP', GDP, 'CO2 Emissions', `CO2 Emissions`) as (Indicator, Value)\")\n\n        # Join DataFrames\n        logger.info(\"Joining DataFrames.\")\n        if \"Country/Region\" in cpi_df.columns:\n            cpi_df = cpi_df.drop(\"Country/Region\")  # Drop duplicate join column from right DataFrame\n            final_df = indicators_df.join(cpi_df, indicators_df[\"Country/Region\"] == cpi_df[\"Country/Region\"], \"inner\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Custom Calculations and Writing to Unity Catalog\n\n# COMMAND ----------\n\n        # Custom calculations\n        logger.info(\"Applying custom calculations.\")\n        if \"Year\" in final_df.columns:\n            final_df = final_df.withColumn(\"Year\", substring(\"Year\", 1, 4))\n\n        # Write the final DataFrame to a Unity Catalog table in Delta format\n        logger.info(\"Writing the final DataFrame to Unity Catalog table.\")\n        final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.target_db.GlobalIndicators\")\n\n        logger.info(\"ETL process completed successfully.\")\n\n    except Exception as e:\n        logger.error(\"An error occurred during the ETL process.\", exc_info=True)\n\nif __name__ == \"__main__\":\n    main()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}