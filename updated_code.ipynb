{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process with PySpark\n# MAGIC This notebook demonstrates an ETL process using PySpark, including data loading, transformation, and writing to Unity Catalog.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql.functions import to_date, col, broadcast\nfrom pyspark.sql import DataFrame\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\ndef reformat_date_fields(df: DataFrame, date_columns: list) -> DataFrame:\n    \"\"\"\n    Reformat date fields to a standard format 'yyyy-MM-dd'.\n    \"\"\"\n    try:\n        for date_col in date_columns:\n            df = df.withColumn(date_col, to_date(col(date_col), \"MM/dd/yyyy\"))\n        logger.info(\"Date fields reformatted successfully.\")\n    except Exception as e:\n        logger.error(f\"Error in reformatting date fields: {e}\")\n        raise\n    return df\n\n# COMMAND ----------\n\ndef standardize_column_names(df: DataFrame, column_mapping: dict) -> DataFrame:\n    \"\"\"\n    Standardize column names to snake_case.\n    \"\"\"\n    try:\n        for old_name, new_name in column_mapping.items():\n            df = df.withColumnRenamed(old_name, new_name)\n        logger.info(\"Column names standardized successfully.\")\n    except Exception as e:\n        logger.error(f\"Error in standardizing column names: {e}\")\n        raise\n    return df\n\n# COMMAND ----------\n\ndef standardize_state_names(df: DataFrame, state_name_mapping: dict) -> DataFrame:\n    \"\"\"\n    Standardize state names using a predefined mapping.\n    \"\"\"\n    try:\n        # Broadcast the mapping for performance if it's small\n        state_name_mapping_broadcast = broadcast(state_name_mapping)\n        df = df.replace(state_name_mapping_broadcast, subset=[\"state_name\"])\n        logger.info(\"State names standardized successfully.\")\n    except Exception as e:\n        logger.error(f\"Error in standardizing state names: {e}\")\n        raise\n    return df\n\n# COMMAND ----------\n\ndef load_data_from_unity_catalog(table_name: str) -> DataFrame:\n    \"\"\"\n    Load data from a Unity Catalog table.\n    \"\"\"\n    try:\n        df = spark.table(table_name)\n        logger.info(f\"Data loaded successfully from {table_name}.\")\n    except Exception as e:\n        logger.error(f\"Error loading data from {table_name}: {e}\")\n        raise\n    return df\n\n# COMMAND ----------\n\ndef write_data_to_unity_catalog(df: DataFrame, table_name: str):\n    \"\"\"\n    Write data to a Unity Catalog table in Delta format.\n    \"\"\"\n    try:\n        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n        logger.info(f\"Data written successfully to {table_name}.\")\n    except Exception as e:\n        logger.error(f\"Error writing data to {table_name}: {e}\")\n        raise\n\n# COMMAND ----------\n\ndef main():\n    try:\n        # Load data from Unity Catalog table\n        input_df = load_data_from_unity_catalog(\"catalog.source_db.source_table\")\n\n        # Reformat date fields\n        date_columns = [\"date_column\"]  # List of date columns to reformat\n        reformatted_df = reformat_date_fields(input_df, date_columns)\n\n        # Standardize column names\n        column_mapping = {\n            \"Date Column\": \"date_column\",\n            \"State Name\": \"state_name\"\n        }\n        standardized_df = standardize_column_names(reformatted_df, column_mapping)\n\n        # Standardize state names\n        state_name_mapping = {\"California\": \"CA\", \"New York\": \"NY\"}\n        standardized_df = standardize_state_names(standardized_df, state_name_mapping)\n\n        # Write the output to a Delta table in Unity Catalog\n        write_data_to_unity_catalog(standardized_df, \"catalog.target_db.target_table\")\n\n    except Exception as e:\n        logger.error(f\"An error occurred during the ETL process: {e}\")\n        raise\n\nif __name__ == \"__main__\":\n    main()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}