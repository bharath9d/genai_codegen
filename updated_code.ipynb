{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fc97a6d-237a-48b1-a844-c1d873458e61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md \n",
    "# MAGIC # ETL Process for Customer 360 Data - demo\n",
    "# MAGIC This notebook performs an ETL process to create a comprehensive Customer 360 view by integrating data from various sources.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "\n",
    "import logging\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "try:\n",
    "    # Step 1: Data Source Configuration\n",
    "    logger.info(\"Loading data from Unity Catalog tables.\")\n",
    "    claims_df = spark.table(\"genai_demo.guardian.claims\")\n",
    "    demographics_df = spark.table(\"genai_demo.guardian.demographics\")\n",
    "    policy_df = spark.table(\"genai_demo.guardian.policy\")\n",
    "    scores_df = spark.table(\"genai_demo.guardian.scores\")\n",
    "    aiml_insights_df = spark.table(\"genai_demo.guardian.aiml_insights\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 2: Data Transformation\n",
    "    # Field Selection\n",
    "    logger.info(\"Selecting relevant fields from each DataFrame.\")\n",
    "    demographics_selected = demographics_df.select(\n",
    "        \"Customer_ID\", \"Customer_Name\", \"Email\", \"Phone_Number\", \"Address\", \"City\", \"State\", \"Postal_Code\",\n",
    "        \"Date_of_Birth\", \"Gender\", \"Marital_Status\", \"Occupation\", \"Income_Level\", \"Customer_Segment\"\n",
    "    )\n",
    "    claims_selected = claims_df.select(\n",
    "        \"Claim_ID\", \"Policy_ID\", \"Claim_Date\", \"Claim_Type\", \"Claim_Status\", \"Claim_Amount\", \"Claim_Payout\"\n",
    "    )\n",
    "    policy_selected = policy_df.select(\n",
    "        \"Policy_ID\", \"Customer_ID\", \"Policy_Type\", \"Policy_Status\", \"Policy_Start_Date\", \"Policy_End_Date\",\n",
    "        \"Policy_Term\", \"Policy_Premium\", \"Total_Premium_Paid\", \"Renewal_Status\", \"Policy_Addons\"\n",
    "    )\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Data Integration\n",
    "    logger.info(\"Joining datasets based on key identifiers.\")\n",
    "    demographics_policy_joined = demographics_selected.join(policy_selected, \"Customer_ID\", \"inner\")\n",
    "    demographics_policy_joined.cache()  # Cache if reused\n",
    "    full_joined_df = demographics_policy_joined.join(claims_selected, \"Policy_ID\", \"inner\")\n",
    "    full_joined_df.cache()  # Cache if reused\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Data Aggregation\n",
    "    logger.info(\"Computing aggregate metrics.\")\n",
    "    aggregated_df = full_joined_df.groupBy(\"Customer_ID\").agg(\n",
    "        F.count(\"Claim_ID\").alias(\"Total_Claims\"),\n",
    "        F.count(\"Policy_ID\").alias(\"Policy_Count\"),\n",
    "        F.max(\"Claim_Date\").alias(\"Recent_Claim_Date\"),\n",
    "        F.avg(\"Claim_Amount\").alias(\"Average_Claim_Amount\")\n",
    "    )\n",
    "    full_joined_df_1 = full_joined_df.join(aggregated_df, \"Customer_ID\", \"inner\")\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Custom Calculations\n",
    "    logger.info(\"Deriving additional metrics.\")\n",
    "    calculated_df = full_joined_df_1.withColumn(\"Age\", F.expr(\"DATEDIFF(current_date(), Date_of_Birth)/365\")) \\\n",
    "        .withColumn(\"Claim_To_Premium_Ratio\", F.expr(\"CASE WHEN Total_Premium_Paid != 0 THEN Claim_Amount/Total_Premium_Paid ELSE 0 END\")) \\\n",
    "        .withColumn(\"Claims_Per_Policy\", F.expr(\"CASE WHEN Policy_Count != 0 THEN Total_Claims/Policy_Count ELSE 0 END\")) \\\n",
    "        .withColumn(\"Retention_Rate\", F.lit(0.85)) \\\n",
    "        .withColumn(\"Cross_Sell_Opportunities\", F.lit(\"Multi-Policy Discount, Home Coverage Add-on\")) \\\n",
    "        .withColumn(\"Upsell_Potential\", F.lit(\"Premium Vehicle Coverage\"))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Comprehensive Data Assembly\n",
    "    logger.info(\"Integrating AI/ML insights and scores.\")\n",
    "    final_df = calculated_df.join(F.broadcast(aiml_insights_df), \"Customer_ID\", \"inner\").join(F.broadcast(scores_df), \"Customer_ID\", \"inner\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "    # Step 3: Output Data\n",
    "    logger.info(\"Writing the final DataFrame to a Unity Catalog table.\")\n",
    "    final_df.show()\n",
    "    #final_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.guardian.customer_360\")\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(\"An error occurred during the ETL process: %s\", e)\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "updated_code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
