{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Global Indicators\n# MAGIC This notebook performs an ETL process on global indicators data using PySpark.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import when, lit, avg, col, broadcast\n\n# COMMAND ----------\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Load Data from Unity Catalog Tables\n\n# COMMAND ----------\n\ndef main():\n    try:\n        # Load data from Unity Catalog tables\n        logger.info(\"Loading data from Unity Catalog tables.\")\n        global_indicators_df = spark.table(\"catalog.global_world_indicators_2000\")\n        consumer_price_indices_df = spark.table(\"catalog.ConsumerPriceIndices\")\n\n        # COMMAND ----------\n\n        # Transformation: Remove Columns\n        logger.info(\"Removing unnecessary columns.\")\n        # Replace with actual column names to be removed\n        global_indicators_df = global_indicators_df.drop(\"UnwantedColumn1\", \"UnwantedColumn2\")\n\n        # COMMAND ----------\n\n        # Transformation: Change Column Type\n        logger.info(\"Changing column types.\")\n        global_indicators_df = global_indicators_df.withColumn(\"GDP\", global_indicators_df[\"GDP\"].cast(\"double\"))\n\n        # COMMAND ----------\n\n        # Transformation: Remap\n        logger.info(\"Remapping column values.\")\n        global_indicators_df = global_indicators_df.withColumn(\n            \"Ease_of_Business\",\n            when(global_indicators_df[\"Ease_of_Business\"] == \"OldValue\", \"NewValue\")\n            .otherwise(global_indicators_df[\"Ease_of_Business\"])\n        )\n\n        # COMMAND ----------\n\n        # Transformation: Add Column\n        logger.info(\"Adding new columns.\")\n        global_indicators_df = global_indicators_df.withColumn(\"NewColumn\", lit(\"DefaultValue\"))\n\n        # COMMAND ----------\n\n        # Transformation: Rename Column\n        logger.info(\"Renaming columns.\")\n        # Replace with actual column names to be renamed\n        global_indicators_df = global_indicators_df.withColumnRenamed(\"OldColumnName\", \"NewColumnName\")\n\n        # COMMAND ----------\n\n        # Transformation: Filter Operation\n        logger.info(\"Applying filters to data.\")\n        global_indicators_df = global_indicators_df.filter(global_indicators_df[\"Year\"] >= 2000)\n\n        # COMMAND ----------\n\n        # Transformation: Range Filter\n        logger.info(\"Applying range filters.\")\n        global_indicators_df = global_indicators_df.filter(\n            (global_indicators_df[\"GDP\"] > 1000) & (global_indicators_df[\"GDP\"] < 5000)\n        )\n\n        # COMMAND ----------\n\n        # Transformation: Aggregate\n        logger.info(\"Performing aggregation.\")\n        aggregated_df = global_indicators_df.groupBy(\"Country/Region\").agg(avg(\"GDP\").alias(\"Average_GDP\"))\n\n        # COMMAND ----------\n\n        # Transformation: Unpivot\n        logger.info(\"Unpivoting data.\")\n        unpivoted_df = global_indicators_df.selectExpr(\n            \"Country/Region\",\n            \"stack(3, 'GDP', GDP, 'Health Exp % GDP', Health_Exp_Percent_GDP, 'CO2 Emissions', CO2_Emissions) as (Indicator, Value)\"\n        )\n\n        # COMMAND ----------\n\n        # Join Condition\n        logger.info(\"Joining datasets.\")\n        # Select only necessary columns to avoid conflicts\n        consumer_price_indices_df = consumer_price_indices_df.select(\"Country/Region\", \"CPI\")\n\n        joined_df = global_indicators_df.join(\n            broadcast(consumer_price_indices_df),\n            global_indicators_df[\"Country/Region\"] == consumer_price_indices_df[\"Country/Region\"],\n            \"inner\"\n        )\n\n        # COMMAND ----------\n\n        # Custom Calculations\n        logger.info(\"Performing custom calculations.\")\n        joined_df = joined_df.withColumn(\"Year_Extracted\", joined_df[\"Year\"].substr(0, 4))\n\n        # COMMAND ----------\n\n        # Write the final output to Unity Catalog table\n        logger.info(\"Writing the final output to Unity Catalog table.\")\n        joined_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.Global_Indicators\")\n\n        logger.info(\"ETL process completed successfully.\")\n\n    except Exception as e:\n        logger.error(\"An error occurred during the ETL process.\", exc_info=True)\n\n# COMMAND ----------\n\nif __name__ == \"__main__\":\n    main()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}