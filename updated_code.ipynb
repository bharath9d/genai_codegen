{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col, when, datediff, current_date, broadcast\n\n# COMMAND ----------\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\ntry:\n    # Load data from Unity Catalog tables\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    policy_df = spark.table(\"genai_demo.guardian.policy\")\n    claims_df = spark.table(\"genai_demo.guardian.claims\")\n    demographics_df = spark.table(\"genai_demo.guardian.demographics\")\n    scores_df = spark.table(\"genai_demo.guardian.scores\")\n    aiml_insights_df = spark.table(\"genai_demo.guardian.aiml_insights\")\n\n    # COMMAND ----------\n\n    # Select relevant fields from demographics data\n    logger.info(\"Selecting relevant fields from demographics data...\")\n    selected_demographics_df = demographics_df.select(\n        \"Customer_ID\", \"Customer_Name\", \"Email\", \"Phone_Number\", \"Address\", \n        \"City\", \"State\", \"Postal_Code\", \"Date_of_Birth\", \"Gender\", \n        \"Marital_Status\", \"Occupation\", \"Income_Level\", \"Customer_Segment\"\n    )\n\n    # COMMAND ----------\n\n    # Join demographics with policy data on Customer_ID\n    logger.info(\"Joining demographics with policy data on Customer_ID...\")\n    joined_df = selected_demographics_df.join(\n        policy_df, \"Customer_ID\", \"inner\"\n    )\n\n    # COMMAND ----------\n\n    # Check for duplicate columns in claims_df and drop them\n    claims_columns = set(claims_df.columns)\n    joined_columns = set(joined_df.columns)\n    duplicate_columns = claims_columns.intersection(joined_columns)\n    claims_df = claims_df.drop(*duplicate_columns)\n\n    # COMMAND ----------\n\n    # Join with claims data on Policy_ID\n    logger.info(\"Joining with claims data on Policy_ID...\")\n    joined_df = joined_df.join(\n        claims_df, \"Policy_ID\", \"inner\"\n    )\n\n    # COMMAND ----------\n\n    # Aggregate data to calculate total claims, policy count, and average claim amount\n    logger.info(\"Aggregating data for total claims, policy count, and average claim amount...\")\n    aggregated_df = joined_df.groupBy(\"Customer_ID\").agg(\n        F.count(\"Claim_ID\").alias(\"Total_Claims\"),\n        F.countDistinct(\"Policy_ID\").alias(\"Policy_Count\"),\n        F.max(\"Claim_Date\").alias(\"Recent_Claim_Date\"),\n        F.avg(\"Claim_Amount\").alias(\"Average_Claim_Amount\")\n    )\n\n    # COMMAND ----------\n\n    # Implement custom calculations\n    logger.info(\"Implementing custom calculations...\")\n    final_df = aggregated_df.join(joined_df, \"Customer_ID\").withColumn(\n        \"Age\", datediff(current_date(), col(\"Date_of_Birth\")) / 365\n    ).withColumn(\n        \"Claim_To_Premium_Ratio\", when(col(\"Total_Premium_Paid\") != 0, col(\"Average_Claim_Amount\") / col(\"Total_Premium_Paid\")).otherwise(0)\n    ).withColumn(\n        \"Claims_Per_Policy\", when(col(\"Policy_Count\") != 0, col(\"Total_Claims\") / col(\"Policy_Count\")).otherwise(0)\n    ).withColumn(\n        \"Retention_Rate\", F.lit(0.85)\n    ).withColumn(\n        \"Cross_Sell_Opportunities\", F.lit(\"Multi-Policy Discount, Home Coverage Add-on\")\n    ).withColumn(\n        \"Upsell_Potential\", F.lit(\"Premium Vehicle Coverage\")\n    )\n\n    # COMMAND ----------\n\n    # Join with AI/ML insights and scores\n    logger.info(\"Joining with AI/ML insights and scores...\")\n    enriched_df = final_df.join(\n        broadcast(aiml_insights_df), \"Customer_ID\", \"inner\"\n    ).join(\n        broadcast(scores_df), \"Customer_ID\", \"inner\"\n    )\n\n    # COMMAND ----------\n\n    # Write the final DataFrame to a Unity Catalog target table\n    logger.info(\"Writing the final DataFrame to a Unity Catalog target table...\")\n    enriched_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.guardian.customer_360\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(\"An error occurred during the ETL process\", exc_info=True)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}