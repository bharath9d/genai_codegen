{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Cardinal Health Data\n# MAGIC This notebook performs an ETL process on data from Unity Catalog tables related to Cardinal Health.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, when, broadcast\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Load Data\n# MAGIC Load data from Unity Catalog tables.\n\n# COMMAND ----------\n\ndef load_data():\n    try:\n        logger.info(\"Loading data from Unity Catalog tables...\")\n        associates_df = spark.table(\"genai_demo.cardinal_health.associates_employment\")\n        compensation_df = spark.table(\"genai_demo.cardinal_health.compensation_guidelines\")\n        hospital_assignments_df = spark.table(\"genai_demo.cardinal_health.hospital_assignments\")\n        logistics_channels_df = spark.table(\"genai_demo.cardinal_health.logistics_channels\")\n        growth_opportunities_df = spark.table(\"genai_demo.cardinal_health.growth_opportunities\")\n        historical_sales_df = spark.table(\"genai_demo.cardinal_health.historical_sales_trending\")\n        hospital_data_df = spark.table(\"genai_demo.cardinal_health.hospitals_stats\")\n        return (associates_df, compensation_df, hospital_assignments_df, logistics_channels_df,\n                growth_opportunities_df, historical_sales_df, hospital_data_df)\n    except Exception as e:\n        logger.error(f\"Error loading data: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Integrate Data\n# MAGIC Integrate data from different sources.\n\n# COMMAND ----------\n\ndef integrate_data(associates_df, compensation_df, hospital_data_df, hospital_assignments_df):\n    try:\n        logger.info(\"Integrating data...\")\n        # Join Associates Employment Data with Compensation Guidelines\n        joined_df_1 = associates_df.join(broadcast(compensation_df), \"Associate_ID\", \"inner\")\n\n        # Join Hospital Data with Hospital Assignments\n        joined_df_2 = hospital_data_df.join(hospital_assignments_df, [\"Hospital_ID\", \"Hospital_Name\"], \"inner\")\n\n        # Join the results of the above joins on Associate_ID\n        final_joined_df = joined_df_1.join(joined_df_2, \"Associate_ID\", \"inner\").cache()\n        return final_joined_df\n    except Exception as e:\n        logger.error(f\"Error integrating data: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Calculate Compensation\n# MAGIC Calculate the compensation for each associate.\n\n# COMMAND ----------\n\ndef calculate_compensation(final_joined_df):\n    try:\n        logger.info(\"Calculating compensation...\")\n        compensation_calculated_df = final_joined_df.withColumn(\n            \"Compensation\",\n            col(\"Base_Salary\") + (col(\"Commission_Percentage\") / 100) * col(\"Base_Salary\") + col(\"Bonus\")\n        )\n        return compensation_calculated_df\n    except Exception as e:\n        logger.error(f\"Error calculating compensation: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Calculate Projected Revenue\n# MAGIC Calculate the projected revenue based on historical sales data.\n\n# COMMAND ----------\n\ndef calculate_projected_revenue(historical_sales_df):\n    try:\n        logger.info(\"Calculating projected revenue...\")\n        projected_revenue_df = historical_sales_df.withColumn(\n            \"Projected_Revenue\",\n            when(col(\"Year\") == 2024, col(\"Sales_Revenue\") * (1 + col(\"Projected_Sales_Growth_Rate\") / 100))\n            .when(col(\"Year\") == 2025, col(\"Sales_Revenue\") * (1 + col(\"Projected_Sales_Growth_Rate\") / 100))\n            .when(col(\"Year\") == 2026, col(\"Sales_Revenue\") * (1 + col(\"Projected_Sales_Growth_Rate\") / 100))\n            .otherwise(col(\"Sales_Revenue\"))\n        )\n        return projected_revenue_df\n    except Exception as e:\n        logger.error(f\"Error calculating projected revenue: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Filter and Sort Data\n# MAGIC Filter the data for target years greater than 2023 and sort by year.\n\n# COMMAND ----------\n\ndef filter_and_sort_data(projected_revenue_df):\n    try:\n        logger.info(\"Filtering and sorting data...\")\n        # Filter for Target Years Greater than 2023\n        filtered_df = projected_revenue_df.filter(col(\"Year\") > 2023)\n\n        # Sort by Target Year\n        sorted_df = filtered_df.orderBy(\"Year\")\n        return sorted_df\n    except Exception as e:\n        logger.error(f\"Error filtering and sorting data: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Write Output\n# MAGIC Write the final sorted data to a Unity Catalog table.\n\n# COMMAND ----------\n\ndef write_output(sorted_df):\n    try:\n        logger.info(\"Writing output data to Unity Catalog table...\")\n        sorted_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.cardinal_health.hospitals_output\")\n    except Exception as e:\n        logger.error(f\"Error writing output data: {e}\")\n        raise\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Main Execution\n# MAGIC Execute the ETL process.\n\n# COMMAND ----------\n\ndef main():\n    try:\n        # Load data\n        (associates_df, compensation_df, hospital_assignments_df, logistics_channels_df,\n         growth_opportunities_df, historical_sales_df, hospital_data_df) = load_data()\n\n        # Integrate data\n        final_joined_df = integrate_data(associates_df, compensation_df, hospital_data_df, hospital_assignments_df)\n\n        # Calculate compensation\n        compensation_calculated_df = calculate_compensation(final_joined_df)\n\n        # Calculate projected revenue\n        projected_revenue_df = calculate_projected_revenue(historical_sales_df)\n\n        # Filter and sort data\n        sorted_df = filter_and_sort_data(projected_revenue_df)\n\n        # Write output\n        write_output(sorted_df)\n\n        logger.info(\"ETL process completed successfully.\")\n    except Exception as e:\n        logger.error(f\"ETL process failed: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}