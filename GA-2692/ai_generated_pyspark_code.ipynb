{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Orders Data\n# MAGIC This notebook performs an ETL process on orders data from various regions, cleans and transforms the data, and aggregates it for reporting.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import DoubleType, StringType\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 1: Data Loading\n# MAGIC Load data from Unity Catalog tables into DataFrames.\n\n# COMMAND ----------\n\ntry:\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    orders_central_df = spark.table(\"genai_demo.citi.orders_central\")\n    orders_east_df = spark.table(\"genai_demo.citi.orders_east\")\n    orders_south_2015_df = spark.table(\"genai_demo.citi.orders_south_2015\")\n    orders_south_2016_df = spark.table(\"genai_demo.citi.orders_south_2016\")\n    orders_south_2017_df = spark.table(\"genai_demo.citi.orders_south_2017\")\n    orders_south_2018_df = spark.table(\"genai_demo.citi.orders_south_2018\")\n    orders_west_df = spark.table(\"genai_demo.citi.orders_west\")\n    quota_df = spark.table(\"genai_demo.citi.quota\")\n    returns_df = spark.table(\"genai_demo.citi.returns\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Combine Orders Data\n# MAGIC Combine all regional orders into a single DataFrame.\n\n# COMMAND ----------\n\n    logger.info(\"Combining all regional orders into a single DataFrame...\")\n    orders_df = orders_central_df.union(orders_east_df).union(orders_south_2015_df)\\\n        .union(orders_south_2016_df).union(orders_south_2017_df).union(orders_south_2018_df)\\\n        .union(orders_west_df)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 2: Data Cleaning and Standardization\n# MAGIC Perform data cleaning and standardization on the combined DataFrame.\n\n# COMMAND ----------\n\n    logger.info(\"Performing data cleaning and standardization...\")\n    orders_df = orders_df.filter(orders_df[\"Order ID\"].isNotNull())\n    orders_df = orders_df.withColumnRenamed(\"Discounts\", \"Discount\").withColumnRenamed(\"Product\", \"Product Name\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 3: Transformation Logic\n# MAGIC Apply transformation logic to prepare the data for analysis.\n\n# COMMAND ----------\n\n    logger.info(\"Applying transformation logic...\")\n    orders_df = orders_df.withColumn(\n        \"Order Date\", \n        F.concat(F.col(\"Order Day\").cast(StringType()), F.lit(\"/\"), \n                 F.col(\"Order Month\").cast(StringType()), F.lit(\"/\"), \n                 F.col(\"Order Year\").cast(StringType()))\n    ).withColumn(\n        \"Ship Date\", \n        F.concat(F.col(\"Ship Day\").cast(StringType()), F.lit(\"/\"), \n                 F.col(\"Ship Month\").cast(StringType()), F.lit(\"/\"), \n                 F.col(\"Ship Year\").cast(StringType()))\n    )\n\n    orders_df = orders_df.withColumn(\n        \"Sales\", \n        F.regexp_replace(F.col(\"Sales\"), \"[^0-9.]\", \"\").cast(DoubleType())\n    ).withColumn(\n        \"Discount\", \n        F.col(\"Discount\").cast(StringType())\n    )\n\n    orders_df = orders_df.withColumn(\n        \"Days to Ship\", \n        F.datediff(F.to_date(F.col(\"Ship Date\"), \"dd/MM/yyyy\"), F.to_date(F.col(\"Order Date\"), \"dd/MM/yyyy\"))\n    ).withColumn(\n        \"Returned?\", \n        F.when(F.isnull(F.col(\"Return Reason\")), \"No\").otherwise(\"Yes\")\n    ).withColumn(\n        \"Year of Sale\", \n        F.year(F.to_date(F.col(\"Order Date\"), \"dd/MM/yyyy\"))\n    )\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 4: Data Aggregation\n# MAGIC Aggregate the data for reporting purposes.\n\n# COMMAND ----------\n\n    logger.info(\"Aggregating data for reporting...\")\n    aggregated_df = orders_df.groupBy(\"Region\", \"Year of Sale\").agg(\n        F.sum(\"Profit\").alias(\"Total Profit\"),\n        F.sum(\"Sales\").alias(\"Total Sales\"),\n        F.sum(\"Quantity\").alias(\"Total Quantity\"),\n        F.avg(\"Discount\").alias(\"Average Discount\")\n    )\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Step 5: Output Data\n# MAGIC Write the transformed data to a Unity Catalog table.\n\n# COMMAND ----------\n\n    logger.info(\"Writing transformed data to Unity Catalog table...\")\n    aggregated_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.annual_regional_performance\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}