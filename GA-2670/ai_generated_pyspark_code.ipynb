{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4e6cd0-ad77-48b4-a0cb-f1364ccbaab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# COMMAND ----------\n",
    "import logging\n",
    "from pyspark.sql.functions import (\n",
    "    col, lit, to_date, concat_ws, regexp_replace, when, datediff, year, sum, avg, split, broadcast\n",
    ")\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# COMMAND ----------\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# COMMAND ----------\n",
    "# Helper function to log DataFrame schema and count\n",
    "def log_df_info(df: DataFrame, df_name: str):\n",
    "    logger.info(f\"{df_name} schema: {df.schema}\")\n",
    "    logger.info(f\"{df_name} count: {df.count()}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "# State abbreviation to full name mapping\n",
    "state_abbr_to_full = {\n",
    "    \"CA\": \"California\",\n",
    "    \"TX\": \"Texas\",\n",
    "    # Add other state mappings as needed\n",
    "}\n",
    "\n",
    "# UDF to replace state abbreviations with full names\n",
    "def replace_state_abbr(state):\n",
    "    return state_abbr_to_full.get(state, state)\n",
    "\n",
    "replace_state_udf = F.udf(replace_state_abbr, StringType())\n",
    "\n",
    "# COMMAND ----------\n",
    "try:\n",
    "    # Load data from Unity Catalog tables\n",
    "    orders_central = spark.table(\"genai_demo.citi.orders_central\")\n",
    "    orders_east = spark.table(\"genai_demo.citi.orders_east\")\n",
    "    orders_south_2015 = spark.table(\"genai_demo.citi.orders_south_2015\")\n",
    "    orders_south_2016 = spark.table(\"genai_demo.citi.orders_south_2016\")\n",
    "    orders_south_2017 = spark.table(\"genai_demo.citi.orders_south_2017\")\n",
    "    orders_south_2018 = spark.table(\"genai_demo.citi.orders_south_2018\")\n",
    "    orders_west = spark.table(\"genai_demo.citi.orders_west\")\n",
    "    quota = spark.table(\"genai_demo.citi.quota\")\n",
    "    returns = spark.table(\"genai_demo.citi.returns\")\n",
    "\n",
    "    # COMMAND ----------\n",
    "    # Transformation: Add Region\n",
    "    orders_central = orders_central.withColumn(\"Region\", lit(\"Central\"))\n",
    "\n",
    "    # Transformation: Add Order Date\n",
    "    orders_central = orders_central.withColumn(\n",
    "        \"Order Date\",\n",
    "        to_date(concat_ws(\"-\", col(\"Order Year\"), col(\"Order Month\"), col(\"Order Day\")), \"yyyy-MM-dd\")\n",
    "    )\n",
    "\n",
    "    # Transformation: Add Ship Date\n",
    "    orders_central = orders_central.withColumn(\n",
    "        \"Ship Date\",\n",
    "        to_date(concat_ws(\"-\", col(\"Ship Year\"), col(\"Ship Month\"), col(\"Ship Day\")), \"yyyy-MM-dd\")\n",
    "    )\n",
    "\n",
    "    # Transformation: Remove unnecessary columns\n",
    "    orders_central = orders_central.drop(\n",
    "        \"Order Year\", \"Order Month\", \"Order Day\", \"Ship Year\", \"Ship Month\", \"Ship Day\"\n",
    "    )\n",
    "\n",
    "    # Transformation: Rename columns\n",
    "    orders_central = orders_central.withColumnRenamed(\"Discounts\", \"Discount\").withColumnRenamed(\"Product\", \"Product Name\")\n",
    "\n",
    "    # Transformation: Exclude rows with null Order ID\n",
    "    orders_central = orders_central.filter(col(\"Order ID\").isNotNull())\n",
    "\n",
    "    # Transformation: Change Discount to string\n",
    "    orders_central = orders_central.withColumn(\"Discount\", col(\"Discount\").cast(\"string\"))\n",
    "\n",
    "    # Transformation: Quick Calc on Sales\n",
    "    orders_central = orders_central.withColumn(\n",
    "        \"Sales\", regexp_replace(col(\"Sales\"), \"[^0-9.]\", \"\").cast(\"double\")\n",
    "    )\n",
    "\n",
    "    # Transformation: Remove Right-prefixed columns\n",
    "    orders_central = orders_central.drop(\n",
    "        *[c for c in orders_central.columns if c.startswith(\"Right_\")]\n",
    "    )\n",
    "\n",
    "    # Transformation: Replace state abbreviations with full names\n",
    "    orders_central = orders_central.withColumn(\"State\", replace_state_udf(col(\"State\")))\n",
    "\n",
    "    # COMMAND ----------\n",
    "    # Transformation: Pivot Quotas\n",
    "    quota = quota.selectExpr(\n",
    "        \"Region\",\n",
    "        \"stack(4, '2015', `2015`, '2016', `2016`, '2017', `2017`, '2018', `2018`) as (Year, Quota)\"\n",
    "    )\n",
    "\n",
    "    # Transformation: Change Year to Integer\n",
    "    quota = quota.withColumn(\"Year\", col(\"Year\").cast(\"integer\"))\n",
    "\n",
    "    # Transformation: Union all orders datasets\n",
    "    all_orders = orders_central.union(orders_east).union(orders_south_2015).union(\n",
    "        orders_south_2016).union(orders_south_2017).union(orders_south_2018).union(orders_west)\n",
    "\n",
    "    # Transformation: Join Orders and Returns\n",
    "    orders_returns = all_orders.join(broadcast(returns), [\"Product ID\", \"Order ID\"], \"right\")\n",
    "\n",
    "    # Transformation: Add Returned column\n",
    "    orders_returns = orders_returns.withColumn(\n",
    "        \"Returned\", when(col(\"Return Reason\").isNotNull(), lit(True)).otherwise(lit(False))\n",
    "    )\n",
    "\n",
    "    # Transformation: Add Days to Ship\n",
    "    orders_returns = orders_returns.withColumn(\n",
    "        \"Days to Ship\", datediff(col(\"Ship Date\"), col(\"Order Date\"))\n",
    "    )\n",
    "\n",
    "    # Transformation: Add Discount Default\n",
    "    orders_returns = orders_returns.withColumn(\n",
    "        \"Discount\", when(col(\"Discount\").isNull(), lit(0)).otherwise(col(\"Discount\"))\n",
    "    )\n",
    "\n",
    "    # Transformation: Add Year of Sale\n",
    "    orders_returns = orders_returns.withColumn(\"Year of Sale\", year(col(\"Order Date\")))\n",
    "\n",
    "    # Transformation: Exclude specific discount range\n",
    "    orders_returns = orders_returns.filter(~(col(\"Discount\").between(17, 18)))\n",
    "\n",
    "    # Transformation: Remove unnecessary columns\n",
    "    orders_returns = orders_returns.drop(\n",
    "        \"Table Names\", \"File Paths\", \"Order ID1\", \"Product ID1\"\n",
    "    )\n",
    "\n",
    "    # Transformation: Clean Notes and Approver\n",
    "    orders_returns = orders_returns.withColumn(\n",
    "        \"Return Notes\", split(col(\"Notes\"), \" \")[0]\n",
    "    ).withColumn(\"Approver\", split(col(\"Notes\"), \" \")[1])\n",
    "\n",
    "    # Transformation: Roll Up Sales\n",
    "    annual_performance = orders_returns.groupBy(\"Region\", \"Year of Sale\").agg(\n",
    "        sum(\"Profit\").alias(\"Total Profit\"),\n",
    "        sum(\"Sales\").alias(\"Total Sales\"),\n",
    "        sum(\"Quantity\").alias(\"Total Quantity\"),\n",
    "        avg(\"Discount\").alias(\"Average Discount\")\n",
    "    )\n",
    "\n",
    "    # COMMAND ----------\n",
    "    # Log DataFrame information\n",
    "    log_df_info(orders_returns, \"Orders and Returns\")\n",
    "    log_df_info(annual_performance, \"Annual Performance\")\n",
    "\n",
    "    # Write to Unity Catalog target tables\n",
    "    orders_returns.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.superstore_sales\")\n",
    "    annual_performance.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.annual_regional_performance\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred: {e}\", exc_info=True)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ai_generated_pyspark_code",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
