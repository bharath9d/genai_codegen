{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Cardinal Health Data\n# MAGIC This notebook performs an ETL process on data from Unity Catalog tables, integrating various datasets and calculating projected revenue.\n\n# COMMAND ----------\n\nimport logging\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, expr, broadcast\n\n# Initialize logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# Assume the Spark session is already initialized as 'spark'\n\ndef main():\n    try:\n        # Load data from Unity Catalog tables\n        logger.info(\"Loading data from Unity Catalog tables...\")\n        associates_df = spark.table(\"genai_demo.cardinal_health.associates_employment\")\n        compensation_df = spark.table(\"genai_demo.cardinal_health.compensation_guidelines\")\n        hospital_assignments_df = spark.table(\"genai_demo.cardinal_health.hospital_assignments\")\n        logistics_channels_df = spark.table(\"genai_demo.cardinal_health.logistics_channels\")\n        growth_opportunities_df = spark.table(\"genai_demo.cardinal_health.growth_opportunities\")\n        historical_sales_df = spark.table(\"genai_demo.cardinal_health.historical_sales_trending\")\n        third_party_trends_df = spark.table(\"genai_demo.cardinal_health.third_party_trends\")\n        company_goals_df = spark.table(\"genai_demo.cardinal_health.company_goals_1\")\n\n# COMMAND ----------\n\n        # Data Integration: Join associates with compensation\n        logger.info(\"Joining associates with compensation data...\")\n        joined_df = associates_df.join(compensation_df, \"Associate_ID\", \"inner\")\n\n        # Calculate total compensation\n        logger.info(\"Calculating total compensation...\")\n        joined_df = joined_df.withColumn(\"Compensation\", expr(\"Base_Salary + (Commission_Percentage * Base_Salary) + Bonus\"))\n\n# COMMAND ----------\n\n        # Join hospital data with hospital assignments\n        logger.info(\"Joining hospital data with hospital assignments...\")\n        hospital_joined_df = hospital_assignments_df.join(hospital_assignments_df, [\"Hospital_ID\", \"Hospital_Name\"], \"inner\")\n\n        # Join logistics channels with growth opportunities\n        logger.info(\"Joining logistics channels with growth opportunities...\")\n        logistics_joined_df = logistics_channels_df.join(growth_opportunities_df, [\"Channel_ID\", \"Channel_Type\"], \"inner\")\n\n# COMMAND ----------\n\n        # Ensure unique records\n        logger.info(\"Ensuring unique records...\")\n        unique_df = logistics_joined_df.dropDuplicates([\"Channel_ID\", \"Channel_Type\", \"Hospital_ID\"])\n\n        # Join historical sales with third-party trends\n        logger.info(\"Joining historical sales with third-party trends...\")\n        sales_trends_joined_df = historical_sales_df.join(third_party_trends_df, \"Channel_Type\", \"inner\")\n\n# COMMAND ----------\n\n        # Calculate projected revenue\n        logger.info(\"Calculating projected revenue...\")\n        def calculate_projected_revenue(df):\n            return df.withColumn(\"Projected_Revenue\", expr(\"\"\"\n                CASE \n                    WHEN Target_Year = 2024 THEN Sales_Revenue * (1 + Projected_Sales_Growth_Rate / 100)\n                    WHEN Target_Year = 2025 THEN Sales_Revenue * (1 + Projected_Sales_Growth_Rate / 100) * (1 + Projected_Sales_Growth_Rate / 100)\n                    WHEN Target_Year = 2026 THEN Sales_Revenue * (1 + Projected_Sales_Growth_Rate / 100) * (1 + Projected_Sales_Growth_Rate / 100) * (1 + Projected_Sales_Growth_Rate / 100)\n                    ELSE Sales_Revenue\n                END\n            \"\"\"))\n\n        final_df = calculate_projected_revenue(sales_trends_joined_df)\n\n# COMMAND ----------\n\n        # Filter data for target years greater than 2023\n        logger.info(\"Filtering data for target years greater than 2023...\")\n        filtered_df = final_df.filter(col(\"Target_Year\") > 2023)\n\n        # Select specific fields for final output\n        logger.info(\"Selecting specific fields for final output...\")\n        selected_df = filtered_df.select(\"Hospital_ID\", \"Channel_Type\", \"Investment_Planned\", \"Sales_Revenue\", \"Market_Trend\", \"Political_Impact\", \"Economic_Impact\", \"Target_Year\", \"Projected_Sales_Growth_Rate\", \"Projected_Revenue\")\n\n# COMMAND ----------\n\n        # Sort data by target year\n        logger.info(\"Sorting data by target year...\")\n        sorted_df = selected_df.orderBy(\"Target_Year\")\n\n        # Write the final processed data to Unity Catalog table\n        logger.info(\"Writing the final processed data to Unity Catalog table...\")\n        sorted_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.cardinal_health.final_output\")\n\n        logger.info(\"ETL process completed successfully.\")\n\n    except Exception as e:\n        logger.error(\"An error occurred during the ETL process\", exc_info=True)\n\nif __name__ == \"__main__\":\n    main()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}