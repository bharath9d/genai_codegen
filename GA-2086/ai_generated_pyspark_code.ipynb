{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# COMMAND ----------\n# MAGIC\n",
                "# Import necessary PySpark functions\nfrom pyspark.sql.functions import broadcast\n\n# COMMAND ----------\n# MAGIC\n",
                "# Assuming final_df, scores_df, and aiml_insights_df are already defined DataFrames\n# Join the DataFrames using broadcast joins for optimization\ncomprehensive_df = final_df.join(broadcast(scores_df), \"Customer_ID\", \"inner\") \\\n                           .join(broadcast(aiml_insights_df), \"Customer_ID\", \"inner\")\n\n# COMMAND ----------\n# MAGIC %md\n# The `comprehensive_df` DataFrame now contains the joined data from `final_df`, `scores_df`, and `aiml_insights_df` using the `Customer_ID` as the key.\n# The use of `broadcast` helps optimize the join operation by broadcasting the smaller DataFrames across the cluster.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}