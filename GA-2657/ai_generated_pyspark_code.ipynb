{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\nimport logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import DoubleType, StringType\n\n# COMMAND ----------\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\ntry:\n    # Step 1: Data Loading\n    logger.info(\"Loading data from Unity Catalog tables...\")\n    orders_central_df = spark.table(\"genai_demo.citi.orders_central\")\n    orders_east_df = spark.table(\"genai_demo.citi.orders_east\")\n    orders_south_2015_df = spark.table(\"genai_demo.citi.orders_south_2015\")\n    orders_south_2016_df = spark.table(\"genai_demo.citi.orders_south_2016\")\n    orders_south_2017_df = spark.table(\"genai_demo.citi.orders_south_2017\")\n    orders_south_2018_df = spark.table(\"genai_demo.citi.orders_south_2018\")\n    orders_west_df = spark.table(\"genai_demo.citi.orders_west\")\n    quota_df = spark.table(\"genai_demo.citi.quota\")\n    returns_df = spark.table(\"genai_demo.citi.returns\")\n\n# COMMAND ----------\n\n    # Step 2: Data Cleaning and Standardization\n    logger.info(\"Performing data cleaning and standardization...\")\n    def standardize_dates(df, order_day, order_month, order_year, ship_day, ship_month, ship_year):\n        return df.withColumn(\n            \"Order Date\", F.concat(F.col(order_day), F.lit(\"/\"), F.col(order_month), F.lit(\"/\"), F.col(order_year))\n        ).withColumn(\n            \"Ship Date\", F.concat(F.col(ship_day), F.lit(\"/\"), F.col(ship_month), F.lit(\"/\"), F.col(ship_year))\n        ).drop(order_day, order_month, order_year, ship_day, ship_month, ship_year)\n\n    def transform_orders(df):\n        return df.filter(F.col(\"Order ID\").isNotNull()) \\\n                 .withColumn(\"Discount\", F.col(\"Discount\").cast(DoubleType())) \\\n                 .withColumn(\"Sales\", F.col(\"Sales\").cast(DoubleType())) \\\n                 .withColumn(\"Days to Ship\", F.datediff(F.to_date(F.col(\"Ship Date\"), \"dd/MM/yyyy\"), F.to_date(F.col(\"Order Date\"), \"dd/MM/yyyy\"))) \\\n                 .withColumn(\"Returned?\", F.when(F.col(\"Return Reason\").isNotNull(), \"Yes\").otherwise(\"No\"))\n\n    def process_orders(df):\n        df = standardize_dates(df, \"Order Day\", \"Order Month\", \"Order Year\", \"Ship Day\", \"Ship Month\", \"Ship Year\")\n        return transform_orders(df)\n\n    # Apply standardization and transformation to all datasets\n    orders_central_df = process_orders(orders_central_df)\n    orders_east_df = process_orders(orders_east_df)\n    orders_south_2015_df = process_orders(orders_south_2015_df)\n    orders_south_2016_df = process_orders(orders_south_2016_df)\n    orders_south_2017_df = process_orders(orders_south_2017_df)\n    orders_south_2018_df = process_orders(orders_south_2018_df)\n    orders_west_df = process_orders(orders_west_df)\n\n# COMMAND ----------\n\n    # Step 3: Data Integration\n    logger.info(\"Integrating datasets...\")\n    all_orders_df = orders_central_df.union(orders_east_df).union(orders_south_2015_df) \\\n        .union(orders_south_2016_df).union(orders_south_2017_df).union(orders_south_2018_df).union(orders_west_df)\n\n    # Ensure 'Year of Sale' is extracted from 'Order Date'\n    all_orders_df = all_orders_df.withColumn(\"Year of Sale\", F.year(F.to_date(F.col(\"Order Date\"), \"dd/MM/yyyy\")))\n\n    orders_with_returns_df = all_orders_df.join(returns_df, [\"Order ID\", \"Product ID\"], \"left\")\n\n# COMMAND ----------\n\n    # Step 4: Aggregation and Output\n    logger.info(\"Aggregating data and writing outputs...\")\n    annual_performance_df = all_orders_df.groupBy(\"Region\", \"Year of Sale\").agg(\n        F.sum(\"Profit\").alias(\"Total Profit\"),\n        F.sum(\"Sales\").alias(\"Total Sales\"),\n        F.sum(\"Quantity\").alias(\"Total Quantity\"),\n        F.avg(\"Discount\").alias(\"Average Discount\")\n    )\n\n    # Write to Unity Catalog\n    annual_performance_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"genai_demo.citi.annual_regional_performance\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(f\"An error occurred during the ETL process: {e}\")\n    raise\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}