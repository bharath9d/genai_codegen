{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Databricks notebook source\n# MAGIC %md\n# MAGIC # ETL Process for Customer Data\n# MAGIC This notebook performs an ETL process on customer data, integrating data from multiple Excel files, cleaning, transforming, and saving the results to a Delta table.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "import logging\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import DateType\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Load Data from DBFS\n# MAGIC Load data from Excel files stored in DBFS.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "try:\n    # Load data from DBFS (assuming the Excel files are already uploaded to DBFS)\n    logger.info(\"Loading data from Excel files in DBFS...\")\n    uk_bank_holidays_df = spark.read.format(\"com.crealytics.spark.excel\") \\\n        .option(\"header\", \"true\") \\\n        .load(\"/dbfs/mnt/data/UK_Bank_Holidays.xlsx\")\n\n    new_customers_df = spark.read.format(\"com.crealytics.spark.excel\") \\\n        .option(\"header\", \"true\") \\\n        .load(\"/dbfs/mnt/data/New_Customers.xlsx\")\n\n    roi_new_customers_df = spark.read.format(\"com.crealytics.spark.excel\") \\\n        .option(\"header\", \"true\") \\\n        .load(\"/dbfs/mnt/data/ROI_New_Customers.xlsx\")\n\n    logger.info(\"Data loaded successfully.\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Data Cleaning and Standardization\n# MAGIC Standardize column names and handle missing values.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Data Cleaning and Standardization\n    logger.info(\"Standardizing column names and handling missing values...\")\n    uk_bank_holidays_df = uk_bank_holidays_df.withColumnRenamed(\"Bank holiday\", \"UK_Bank_Holiday\")\n    new_customers_df = new_customers_df.fillna({'New Customers': 0})\n    roi_new_customers_df = roi_new_customers_df.fillna({'New Customers': 0})\n\n    # Ensure date columns are in the correct format\n    new_customers_df = new_customers_df.withColumn(\"Date\", F.to_date(\"Date\", \"yyyy-MM-dd\"))\n    uk_bank_holidays_df = uk_bank_holidays_df.withColumn(\"Date\", F.to_date(\"Date\", \"yyyy-MM-dd\"))\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Data Integration\n# MAGIC Join datasets to integrate data.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Data Integration\n    logger.info(\"Joining datasets...\")\n    integrated_df = new_customers_df.join(roi_new_customers_df, \"Reporting Date\", \"inner\") \\\n        .join(uk_bank_holidays_df, new_customers_df[\"Date\"] == uk_bank_holidays_df[\"Date\"], \"left\")\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Add Custom Fields\n# MAGIC Add custom fields to the integrated dataset.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Add Custom Fields\n    logger.info(\"Adding custom fields...\")\n    integrated_df = integrated_df.withColumn(\"Reporting Day\", \n                                             F.when(F.col(\"Day\").startswith(\"S\"), \"N\")\n                                             .otherwise(F.when(F.col(\"UK_Bank_Holiday\").isNull(), \"Y\").otherwise(\"N\")))\n\n    # Construct UK Bank Holiday date\n    integrated_df = integrated_df.withColumn(\"UK_Bank_Holiday\", \n                                             F.to_date(F.concat_ws(\"-\", F.col(\"Year\"), F.month(\"Date\"), F.dayofmonth(\"Date\")), \"yyyy-MM-dd\"))\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Aggregation and Business Rules\n# MAGIC Aggregate metrics by month and region.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Aggregation and Business Rules\n    logger.info(\"Aggregating metrics by month and region...\")\n    aggregated_df = integrated_df.groupBy(F.month(\"Reporting Date\").alias(\"Reporting Month\"), \n                                          F.year(\"Reporting Date\").alias(\"Year\")) \\\n        .agg(F.sum(\"New Customers\").alias(\"Total New Customers\"))\n\n# COMMAND ----------\n\n# MAGIC %md\n# MAGIC ## Output to Delta Format\n# MAGIC Write the final processed data to a Delta table.\n\n# COMMAND ----------\n\n# MAGIC\n",
                "# Output to Delta format for better performance\n    logger.info(\"Writing the final processed data to a Delta table...\")\n    aggregated_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"catalog.target_db.new_customers_ready_to_report\")\n\n    logger.info(\"ETL process completed successfully.\")\n\nexcept Exception as e:\n    logger.error(\"An error occurred during the ETL process\", exc_info=True)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}